

	*** High pri ***
	
		Make functionality to patch in data from a sub-model in a data set.
			E.g. you have a setup for Simply+NIVAFjord and you want to patch in from a different file that just has the Simply part of the setup.
			Should not be an "include" on file level, because that causes too much ambiguity about how this should be saved if overwritten.
			Instead, make it an explicit operation accessible from API (thus MobiView2 and/or mobipy).
			void patch(Data_Set *target, Data_Set *source); // Or something like that.
				Not that straightforward due to
					Can't just copy over data, need to update all internal cross-references.
						Maybe unless you patch from a text file and parse it from scratch instead of patching with an already parsed object.
					Conflicts must be handled. For instance, must check that index sets that are in both data sets agree.
			
			Reason why we want this: often you calibrate the catchment separately (runs much faster alone), then want to combine the new results with the full basin model.
				Is currently done with text copy pasting, but can be a bit tiresome.
	
		We need an all_in_flux and all_out_flux or similar.
			For instance, SimplyP could be broken if it is used with soil discharge along a connection since it uses out_flux (and it can't know about the connections).
		
	
		If you load different modules using the same load name, you don't get a name clash!
			This is as intended if the two loads are identical (so that you can extend two models that load the same module)
			Fixed if the module template is different, but should also be fixed when template is same but load arguments are different.
				Complexity because e.g. two 'loc' arguments could be different declarations but have the same "value". Same for any inlined declaration.
			
		Document how to use connections, and some more of the advanced concepts.
		
		Figure out if there is a memory leak when running MCMC in python.
			Or otherwise why it crashes on very large runs
		
		mobipy
			
			Can't load mobipy from Anaconda on Windows (dll doesn't load properly)
				It is probably more complex than it not finding vcredist dependencies.
		
		Add forums on github page? (github Discussions)
		
		Specific models
		
			MAGIC: 
				
				SolveFreeFluoride can go into an infinite loop if F is small, but this depends on Al.
				
				We should be more careful that concentrations don't go negative.
				
				How to fix it so that runoff is scaled correctly wrt rel_area automatically, not relying on a separate user-set parameter.
				Difficult without some kind of sum_above or aggregate_above(rel_area, con) for graph connection.
					But we could make that.
					It is sort of like an in_flux_connection, except not for fluxes.
					Importantly, this should not have the agg_weight applied, but that could be confusing??
					It could be an aggregation for the edge compartment (if we make one)
				Or make the user input a separate runoff scale.
				Problematic to compute in cases where you have split runoff or if it is vertical, not horizontal.
				
			Use 'option's to combine airsea_fpv and airsea_fpv_simple
				Put them in the main airsea file.
			
			Lots of duplication between the different airsea things in general.
				The FPV versions should be able to reuse some of what is in the plain versions without code duplication.
			
			NIVAFjord
				
				Vertical wind mixing using B-V. See page 45 in report 4.
				
				Add wind induced horizontal transport. (Original model: 3% of wind component along the normal of the boundary. Decreases linearly in depth to a given depth)
					(Need 2 wind components as inputs. The current 'ecosystem' of other modules is not configured for that. But should be easy to fix. Just make a air.wind that computes the vector length of the two components in the case where you load this module.)
				
				DIC in nivafjord boundary (when DIC is enabled).
						
				Need a complete rethink of horizontal fluxes. They cause too much numerical instability when there is large in/outflow for small layers.
					There should really be an error if there is an opening to a neighboring basin on a depth below the max depth of that basin.
					Moreover, they need to be proper two-way for the layer switching to work in both directions.
				
				Go to the simpler version from MyLake of parametrizing vertical mixing
					Mathematically the same, just removes unnecessary parameters
					Allows us to compare with MyLake setups.
					See guide chapter 07 for an implementation
				
				Finish biochemistry.
					Relegated to if we need it in an application probably
						Do we need separate NH4? Do we need Si?
						Sulfate reduction?
						Zooplankton?
						Experiment with different phytoplankton formulation.
			
		Connection system
		
			Have to figure out what something like
				flux(blabla, something[vert.below], ...)				
			means. Right now the location 'something' is not used, and we only need to declare it to allow [.top] or [.specific] etc on the secondary restriction.
				Need this for NIVAFjord
			# (Could later extend it to have different code depending on the target (for graph).)
					
					Ideally we don't want this at all, the target should be specified in the connection data only. But that causes a problem for dynamically computed indexes of grid1d when grid1d is secondary restriction.
						
			
			Check if it is valid to look up a value along a connection.
				Done except for parameters.
			
			graph connections
				
				Regex
					Maybe just remove this feature since it is too complex for the value we get out of it.
						Just keep the necessary parts like checking what compartments are allowed and no cycles in case of no_cycles.
				
					Finish regex check in the general case (cycles case)
					
					Regex checking of fjord_horizontal regex is bugged for nivafjord_moss
						if the regex is switched to
						river | (river? layer+ bnd_layer?)
						it fails, so the | operator is not symmetric somehow.
					also it doesn't fail if there is an ->out on the downstream data even though that should not be allowed by the regex.
				
				For [below] accesses in code, we probably need to pre-process them to check that the units are the same in all instances etc.
					Is currently done in codegen (put_var_lookup_indexes).
					May have to be done inside resolve_function_tree, in that case need to access the connection data there.
					
				When it accesses [below] across an index set that has a sub-index set, it should check that the sub index set is not out of bounds (if the variable depends on it).
					Probably put in make_restriction_condition().
					Right now it doesn't break because the data is allocated and has value 0, but that may not be the case eventually.
						Moreover it would be wrong if it was a flux with that target and not set to 0 for some other reason.
				
				Make it work with quantities as the node component.
					And allow aggregation weight for quantities (can for instance be used for degradation chains of isotopes or POPs where some of the mass goes away as side products).
						Although that could just be done with an additional ->out branch.

			grid1d
			
				When the context location of code is e.g. [vert.top], it should be implicit that all variables are accessed with that index.
					In that case it should also be possible to look up [vert.below] inside this code (which then resolves to index 1).

				The way we go around not having a source_aggregate for these when we have something going from [below] (and maybe from [top] if that works now) is not clean and could cause problems if people want to use the in_flux aggregate in the code.
				However it also seems like a waste to make a out_flux aggregate when it is only needed for one of the indexes.
					Unless we make a special system for it not to have an index set dependency on the grid index in this case. That seems like a lot of work for this special case though.
					- It is actually not that much of a waste since they are now usually @no_store.
				Alternatively, in the ODE codegen, directly make a subtraction of the flux (on condition of correct index).
					This is maybe the easiest, but is still a bit of work for this special case.
					
				Actually in grid1d the connection aggregate is always unnecessary unless it is referenced. Would it be better to remove it as a default and only generate it if it is referenced in code by in_flux(connection)?
				
				Need a guard for when you have flux
					flux(a.something, b.something[conn.top])  (or bottom or specific)
					or similar if the node index set for conn has a parent index set that a does not depend on.
					This should either not be allowed or there should be a mitigation (currently internal error)
			
			
			.specific target:
				Maybe the @specific code AST should be tied to the var loc instead of the variable, like var_ident[conn_ident.{ ..code }]
					Could then also allow .specific access inside main code, not just in flux source/targets
						Also makes it easier to do random access indexing in general in case people really want it.
						Creates a bit of a dependency nightmare?? Must maybe assume that it creates same dependency as 'above', otherwise would need to analyze the code..
				Only issue is then that copying around Specific_Var_Location can then incur a tree copy of that code.
					Although maybe not necessary if we make an external owner of it? Then we could just copy the pointer.
					
				Tridiagonal distribution of flux target as in original NIVAFjord (?).
			
		Bidirectional
			Should check that target unit is the same a source unit always (and not allow unit conversions (except time-related ones))
				Both for main and dissolved fluxes.
				And maybe not allow unit_conversions and aggregation_weights (or otherwise multiply by the inverse when necessary).
				
			Have an optional test to see if non-bidirectional non-mixing fluxes (with dissolvedes) were negative after or during a run.
			
			Need to check that a bidirectional flux wasn't discrete.
		Note: unit_conversion seems to work fine for @mixing, but we should test it properly. Also, it probably depends on the computed concentration in that expression being the same for dissolved ones (just not the mass variable). That is maybe also the case for @bidirectional.
	
	
	*** Intermediate-pri ***
	
		Got an (internal) error in the following case (nivafjord pipe boundary model)
			flux(bnd.water, layer.water[vert.specific]) ...
			
			bnd.water.tox can be distributed over tox_index, but that dependency was ruled out due to lack of differing parametrization
			layer.water.tox was distributed over tox_index with the actual dependency.
			Caused problem when the dissolved flux were to be added to the connection aggregate (lack of index set).
				Probably also a problem for vert.top etc.
				It is a bit tricky for the framework to predetermine this.. But there is maybe something like this for graph aggregates already that could be applied here too.
	
		If an input series is provided indexed over "subcatchment", but should be indexed over "water body" and "subcatchment" is a union member of "water body", that should be made to work. (and all similar cases) Just re-map the index.
		
		Store name of expected model file in data sets (?)
			Done now as a comment, for documentation purposes only.
			Could make it more structural, allow loading that file only, and it infers the model it needs.
				Would probably only work if it is in /Mobius2/models/
		
		It may be confusing to users what arguments are available for 'option'. This is because if you use a declared identifier that has not been processed yet, it will say that it doesn't recognize the identifier. It is legitimate that there is an error, but the error can't (for resons) acknowledge that the identifier exists but is not usable in this context.
		
		We could probably simplify a lot of things by switching from our custom String_View to std::string_view ??
	
		MobiView
			We could allow editing option_group parameters in MobiView
				Use a similar recompile system as for constant parameters.
				Difference is that you also need to reload the model in this case.
	
		Get rid of the idea of aggregating to a *compartment*. Instead, only aggregate to the index set tuple.
		This work has already been started.
			Remaining issues:
				Serialization name depends on compartment, should depend on index set tuple (should be easy to change)
				aggregation_weight depends on compartment. Make it work like unit_conversion instead?
			Right now there may be a problem if you get two different aggregations to the same compartment but to different index set tuples.
	
	
		Make something like
		
			# Possible to assign to (property) state variables here. Takes responsibility for that state variable just like a result() in an
			# external_computation
			computation("A computation", soil) {
				soil.conc_so4 <- something,
			}
			This way we could port all of MAGIC to Mobius2 and not call out to a C++ external_computation for it.
				Although it would be annoying to do the equilibrium constants without array and struct syntax..
	
		Not possible to scope into a preamble from model scope. Should do this in a good way. Can't always export the preamble to model scope.
			Maybe we should always scope into preambles using the . syntax? (Also when they are passed to modules?).
				Doesn't quite work since you can declare properties which should be possible to compose with others.
				In that case would require different syntax for scoping into preamble.
			Use cases are
				Pass a parameter from a preamble to a module without passing the full preamble. (Typically when it is passed as a loc() and the module doesn't care what type it is)
					Can be taken care of by wrapping it in a property (not ideal)
				unit_conversion and aggregation_weight refering to parameters in preambles.
					Allow declaring these in (global) modules?
			What about having a note for extracting symbols from preambles?
				p : load("preamble something") @use(a, b, c) #Passes a,b,c into the loading scope.
					Has the problem of potentially causing naming conflicts in the loading scope, but that is a problem with preambles in general. Do we want to fix that?
					We could do something like
						@use(a, b2=b, c) ... # (requires new syntax type for the AST, but would also be nice to have for passing load arguments to modules).
					and also require that when a module takes a preamble as an argument. So that the module can control what the symbols are called in its own scope (and also what symbols it expects to get from what preamble).
	
		Would be very useful to be able to turn on an option to store out what variables are causing error control to reduce step size.
		Also, get the average step size through the time step, not just the last one.	
			Requires a lot of extra infrastructure for this to be possible though.
	
		Make it possible to directly overload a concentration through an input series, not requiring it to be a separate 'property' declaration.
			Turned out to be very difficult due to how things are organized, and caused a totally unrelated series to become NaN.
				May have messed up indexing of series values?
	
		Position_Map
			There can be problems if the max depth doesn't exactly match a boundary of two widths.
				See for instance Breiangen in nivafjord_moss
			Was this solved?
		The way positioned indexes are named in get_index_names is not going to work for serialization.
			May need to separate between serialization name and display name for these.
				Actually, right now indexes are serialized by number and not name any way, so it is not a problem?

	
		MobiView
		
			Circumstantial bugs, not repeated yet:
				Calibration stats and observed stats bugging out in fjord layers.
				2d plot doesn't work when only certain layers are selected. For instance the 2-3 first layers.
			
			2d plot: The plot won't make sense at all unless the selected indexes is one single contiguous interval (that ideally starts at 0).
				Make MobiView print an error if it isn't?
				
			Make model reloads work better wrt 'quick_select'.
				If the quick_select tab is open, it should choose the right thing back.
			Maybe quick_select should disable separate selection of input series.
								
			Seasonal aggregation.
				I.e. the mean for jan, feb, ... across multiple years.
				Maybe with box plot.
				
			Make it so that editing map based parameters works when the last index is not position based (?)
	
		
		For sub-indexed index sets, don't allocate the entire max size for each instance (for data blocks).
			This would require a very large system rewrite of the storage system.
			Complicates indexing computations, but can be a huge memory saver in some NIVAFjord setups.
			
		For additional_series data it is very wasteful that it allocates the max vector even though most of it is going to be nan. Esp. for fjord data that has many empty layers.
			Could make an entire separate system for how these are stored, but a lot of work, esp. taking into account that it has to fit into how MobiView/mobipy work.
			
			
		Ideally we should always (automatically) check if an entity we reference has_been_processed (unless we expect it not to be as during the construction step).
	
		process_series_data	
					
			Allow averaging input values that are assigned to the same time step (makes it easier to work with different step sizes.)
				Have to be more careful that we don't do double assignments during interpolation in that case.
				Is there a way to do it without double allocation during setup?
				
				What we really want this for is just when indexes of the same series are provided multiple times.
				
				
			Keep track of max and min dates for given model input series separately and test against that when starting model run (only need to test against intersection of the intervals)
				A bit tricky if they are interpolated (?). In fact it is difficult to determine the intersection interval if any model inputs are interpolated.
				
				It is only really relevant for some series. In some cases it is ok if provided data doesn't cover the entire interval.
			Clear model input series to NaN outside the individual interval.
				What to do if an input is interpolated and not 'inside'?
	
		Should have better processing of docstrings.
			Right now they must be tabbed entirely to the left or otherwise the tabs inside the string is recorded.
				Should be easy since we can do it when they are copied over to std::string. Just keep track of the indentation of the first line and subtract it from subsequent ones (assuming they are indented with the same method).
	
	
		Data_Set
			Need a resize() function on the Data_Set or something like that, which updates all data based on new indexes for the index sets.
				Must go through everything that is indexed and delete items that are attached to removed indexes.
					parameters, connections, input series.
						anything else?
			
			Make it possible to make a data file that is referring to another one, but with a subset of the indexes.
				Just uses reshape after loading the Data_Set in the one referred to.
			e.g.
				data_set @subset("other_file_name.dat") {
					index_set() ....
				}
				Have to decide what to do with broken connection arrows.
			
			Make it possible to have a data file extend another one.
				The problem is how the 'save' functionality will work for that...
				Also may want @except on this too. (For instance for connections that could be different in the extending file).
			
		Allow index sets to be empty (needed for above to work).
			Invalidate state variables that are dependent on empty index sets.
			e.g. allows you to run EasyLake-SimplyCNP without lakes, which can be useful if you are working with a data set subset.
			
			Probably a lot of work, will introduce bugs everywhere.
		
		
		@no_store :
				
			May need a more granular system for specifying what series to store (for non-declared series).
				Like have a store() declaration in the Data_Set.
			
			Determine variables that are going to be run-time constant and just compute them in the initial step, not the rest. (Also goes for stored variables).
				Not allowed for ODE quantities.
					Due to difficulty of determining what it will look like before the code generation step (the way it is set up now).
				A bit annoying if the @initial code for it is different from the main code..
					Probably we can't do this in that case.
				
				Could also be done for variables that are not @no_store in the outset. They could be promoted as no_store.
					Although that is annoying since then they don't show up in the interface.
		
	
		Right now you get warning if you load a library that loads another library, but you don't use all the functions of the first library so that the second library is not referenced in active code.
			Maybe just don't give intra-library warnings, or instead process all the functions somehow, but that is tricky.

		
		
		What to do with discrete fluxes when varying step size.
			They are currently not step size independent.
			Should they be re-scaled somehow if the step size is different from the one that is declared in the flux?
				That would only be correct if the flux is linear in the state variables.
			
		What to do about things like (computed) global radiation that should really have an hourly variation with low step sizes but should be averaged with higher?
		
		Union index sets.   Update: this probably is correct now??
			say     a : index_set("A") @union(b, c)
			We probably have to disallow dependency on a if you have dependency on both b and c, or it is ambiguous.
				Already fixed for direct dependencies (parameters, index sets)
				On what level do we check this? Must be during the resolution loop?
			A Var_Location should not be able to both depend on a union and a member of that union
				This is currently checked per component basis, but not combined. Should be done in model_composition
			Declaring a union index set before one of its members may break index processing.
		
		Clean up the prune_tree system.
			Could get rid of using Function_Scope in prune_helper?
				Tried it, but it has a bug.
			Easy to have leaks when moving and deleting nodes the way it is done now.

		Normalized file paths can be different depending on how they were loaded using relative paths. This causes it some times to try to load the same library twice, which causes a name clash.
			Need a fully standardized normalized path.

				
		error_print_location
			Make it print the bracket if needed.
			To make it completely correct we would need to store the scope_id in every Var_Location. Consider it?
				May be needed anyway if we put .specific code AST directly in the Var_Location.

		More on module loading and the declaration format:
				
			Dynamic module choice (based on data set)
			
			
		The way we handle regular_aggregates of fluxes is a bit confusing when maintaining the framework.
			
		Go over and improve diagnostics in error messages (all over the place).
		
		external_computation :
			Lots of things to make less error prone, but...
			Just do whatever is needed when it is needed
			It is only used for NIVAFjord for now.
			
		Many times if some code depends on .below, it has a branch per lookup.
			Could instead detect if the code depends on .below and then do a branch of the code total.
			Also, could make existing_condition work for graph lookups better I think (?).
		
		The clamping of .specific expands the generated code a lot since it is done on every lookup. Maybe instead it should be tracked as a single state variable that is clamped, and just reference it.
			Not possible for .specific in code (if we allow that), only if it is the target of a flux.
		
	*** Low-pri ****
	
		Module arguments that are ruled out by options should not give dev. warnings.
			(But this is tricky to fix, as otherwise we would have to process these declarations).
	
		We could "autobox" locs. I.e. let a parameter be a valid loc argument.
	
		Add NetCDF4 i/o
	
		Version numbers on libraries?
			Doesn't really have any function unless the model specifies what version it is loading, but that seems a bit too complex.
	
		When something is @override_conc we could just drop computing the mass variable whatsoever. It doesn't seem to be interesting to have.
			It could technically be referenced in code, that is the problem. We would have to detect for that.
	
		Multiple solvers:
			Eventually may want/need to codegen smoothing or means. That is if a solver looks up something from another solver, it should linearly interpolate between last() value and current value using the time.fractional_step
			May also want to compute (volume-weighted) means.
		
		Clean up the sorting algorithm
			Make it independent of the Mobius framework code (no direct error exits, instead have error codes).
	
		Solution of the solver step resolution output issue is not ideal. Not that good to cap try_h to 1 since it changes the dynamics of the solver in subsequent steps.
	
		Have a special state variable type that can record solver step resolution.
			Would only record what it ended at in that step though
	
		Datetime algorithms are slow for large dates
			Low priority since it really only comes into play if the user makes a mistake and zooms the plot in MobiView2 to much. We are normally not working with such large dates.
	
		In the tree pruning, try to merge local variables that are identical.
	
		'iterate' in function scope.
			Make the iter_tag be referencable as a value.
			
			i:{
				a <- a*2,
				a         if i > 10,
				iterate i otherwise
			}
			
		Maybe implement reverse iteration for grid1d
			if you have a property depending on the [below] of itself.
			Tricky since it would imply a complication of the instruction and index set dependency system for a very small special case.
	
		
		Could also have flux(source, target) like in_flux, out_flux, but just summing between these locations.	
	
		Give proper error when externally linked function is not found.
			Currently it just doesn't compile the module functions, and only gives error when trying to look up the module functions saying *they* are not found.
			Not sure how to fix it, may have to delve into orcjit.

		Is there any way we could simplify 'aggregation_weight' and 'unit_conversion' so that they don't have to be declared like that?
		
		It can sometimes be very difficult to debug what is going on when one forgets to put a quantity on a solver and this doesn't give an error for dependency reasons.
		
		Current override system of inputs on properties is not the best. Should be possible on a per-index basis (but that requires something like input_was_provided in Mobius1)
			Similarly also want to allow inputs to override parameters.
				This is tricky to do implicitly due to how parameter names are scoped. May need a if_input_else_parameter() or something.
		
		MobiView:
		
			Plot
				
				More aggregation intervals
					minute, hour, day. (esp. day).
				
				Figure out a way to make 2D plot faster
					Make it not need to update the data source if plot setup was not changed.
					Improve the drawing algorithm in ScatterDraw.
						Looks like the problem is the way TableData finds the index of a point. (For each pixel lookup, it has to iterate through a large portion of the table).
							Could make binary search, or something else.
						Also make it allow custom color gradient functions.
					Maybe:
						Make a date range for the 2D plot (when the date is the x axis) that defaults to no more than say 1000 steps (?)
							Plot is just generated for this range.
				
				stacked_share has a slow implementation.
					Should maybe not sum over all the values each time it is extracted, just do it once and store it.
				Normalized axis needs to be more robust.
				Flickering axis labels when scrolling.
				
				"Network" plot for connections. Draw the network along with amount (of some quantity(ies)) as bar plot per node. Animate over time.
					Maybe not just for connection, but for any graph of that quantity (including regular fluxes)?
					Allow multiple bars for several quantities or instances of quantities.
					
				How to do unit of sum of reach flow if the reach flow unit is in m3/s and the sum is over days?
				Could have both aggregation none and days, and in the later case it also aggregates m3/s -> m3/day .
					A bit annoying do it from a coding perspective though because you have to work with declared units, not standardized units.
					
				Trend line doesn't make sense for some aggregations.
					For sum, the trend is not the trend of the sum ..
				Make the residual trend one of the available residual statistics (in terms of optim. it should be minimized in absolute value).
			
			Sensitivity & optimization - new features
				
				Make the code better so that it is not so easy to have bugs when adding/removing/moving parameters.
				Combine simple sensitivity into the advanced sensitivity setup.
					Compute statistics of the target stat like variance etc.
					Allow for 2 parameters, with a surf plot eventually.
				Serialize sensitivity setups using a Mobius format instead of json so that we can load the same setups in mobipy eventually.
				More customizable target functions.
				Targets computed from aggregate series (stats of aggregate series).
				
				Optimizer callback doesn't update additional plot view.
				
				Selection of matrix column parameters is incorrect (when you click them).
					Only when you switch from one col to another in the same row. Can only be completely fixed by moving to using GridCtrl.
				
				Implement the MCMC sampler from
					https://www.econstor.eu/bitstream/10419/268226/1/1830478958.pdf
				Also maybe other samplers.
				GLUE-like sampling?
					Issue then is that parameter distribution is not determined by frequency alone, but by weight. Need to update much of the code for that.
				GLUE-like likelihood functions?
				
			Something where you can plot individual functions / state vars as functions of their inputs.
			
			Finish all missing functionality from MobiView1
				Index set editing (Will now include connection editing).
					Use Data_Set reshape functionality when that is included
								
			tweaks to the state var tree organization
				The icons in "by quantity" view are currently not that intuitive.
				Allow order by flux? By module?
				
			
			
		
		More mobipy functionality.
			Multidimensional slices and strides
			Slices for parameters (setting and getting)
			Saving to file (incl saving inputs, but that should be a core Mobius2 feature).
			More python wrapper stuff from Mobius1.
		
		Some kind of system for specifying assertion checks on user provided data, such as
			lu_prop should sum to 1 over landscape units.
			Some parameter bounds are absolute.
	
	
		Make it possible to free file memory before a model is deleted.
			Requires ASTs to copy some string data, which is a bit annoying since right now they store Tokens directly (which contain String_Views to file memory).
			May need a way to copy String_View values over to a separate buffer for all tokens in ASTs.
			Or the ASTs just store a new struct that contains much the same as Token, but has std::strings instead.
		
		Set units of regular aggregation state variables so that they display correctly if viewed.
			note that it is a bit tricky for fluxes.
			
		aggregate() of series and parameters, or even of arbitrary expressions.
			For parameters, ideally it should just be computed once using the constant system described above.
			For arbitrary expressions, it could be tricky to figure out what compartment it actually aggregates from.
		
		Make discrete fluxes work like other fluxes for aggregation stuff so that everything works the same way for them (including some connection stuff).
			Reimplement discrete fluxes for connections in some situations.
				Should always be possible for grid1d.
				Also for graph if it is no_cycles and we force those to be ordered correctly.
			This may not go well with the above suggested change though.
		
		Would like to get the assembly code for the model, but it is apparently notrivial. Can get the obj by using a dummy object cache that dumps the memory
			https://github.com/llvm/llvm-project/blob/main/llvm/examples/OrcV2Examples/LLJITWithObjectCache/LLJITWithObjectCache.cpp
			One could then manually disassemble it.
		
		Other solver algorithms.
		
		Declaring units with a handle and reusing that handle does not quite work, at least not for parameters.
		
		last(something) doesn't automatically cause it to have an initial value computation (if one was not set).

		Re-consolidate input loading with the serialization system (In terms of how it looks up ids of names).
			Tricky...
			
		Allow accessing e.g. conc(water.sed.phos, water) in code? Probably unnecessary ( since it is equal to conc(water.sed.phos)*conc(water.sed) )
		
		
	Probably not ?:
	
	
		Error: We can't find a way to convert between the declared concentration unit mg l⁻¹ and the computed concentration unit kg ha⁻² mm⁻¹.
			It should be able to do that..
			- I was not able to reproduce this bug...
	
	
	
		Do reassignable local vars with phi nodes instead of alloca.
			LLVM optimizer seems to figure this one out, so it is not that important.
	
		Consider just adding connection fluxes to derivatives as they are computed instead of having so many aggregates (except when these are actually needed, which would be only when we explicitly look up the in_flux).
					This would be a major change, but could create some speedup.
					Maybe not that necessary now that they are @no_store by default.
	
		System for specifying different display variants (along with the code in MobiView2 to make use of that).
			E.g. say if a variable should not be displayed in MobiView2 (but have a display all checkbox button that re-enable them)
			Maybe not really needed, @no_store is probably sufficient.
	
		If a dissolved substance can flow somewhere, you don't have to declare that it is there (?)
			Maybe only if you specify it to disperse.
			could be tricky wrt units.
			could be tricky since right now we assume all quantities are declared.
			how to determine initial value?
			sometimes you don't want it there (though that could be accomplished with no_carry)
	
		Selecting profile or profile2d should select all the indexes if only one index set is active and only one index is selected.
			Maybe not desirable
	
		The "loose depends" system is kind of iffy.
			I think there are no guarantee that something is not placed in a for loop too late initially. Esp. bc of how create_batches works.
				This in particular may have been fixed now.
				
		Load modules from modules (?)
			Probably difficult wrt. multiple loads of the same base module. Unless we also scope the module names recursively.
			Doesn't seem to be that necessary.
	
	NOTES
		
	Hope for reply on one of these 
		https://discourse.llvm.org/t/how-to-generate-ir-so-that-the-loop-vectorizer-can-vectorize-it/69096/2
		https://stackoverflow.com/questions/75674759/llvm-loop-vectorizer-does-not-vectorize-my-ir?noredirect=1#comment133504571_75674759
		