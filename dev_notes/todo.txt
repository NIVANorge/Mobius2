

	*** High pri ***

		Why do errors during data set saving crash the program instead of getting caught now?
		
		Move over to having Mobius_Model as a Catalog. Then Data_Set.
			
			Is it worth it to introduce a concept of data_type (which is map_list, graph) already at the ast parsing stage?
				Yes, doing it.
				TODO: finish.
			
			Standardize so that model and data_set loading are both in a read_from_file function on the class itself.
			
			Make a separate .cpp file for data set writing. Standardize it somewhat (i.e. just walk the ast tree).
			
			Have to do something with Index_Set_Declaration::process_declaration() that allows it both to parse Data_Set and Model.
				Unless we manually remember to do that when registering index sets during the Data_Set processing.
			
			
			
			Need to figure out what to do with has_been_processed (is it necessary for anything other than libraries and modules?)
			
			
			Remove templatization of index_data on Record_Type (and put a lot of the code in index_data in a .cpp for faster recompilation).
			Instead just have separate Reg_Types for Data_Set and Mobius_Model things. (?)
				After this is done, move to Index_Set_Tuple for union_of also.
				It would be nicer if index set is always the same Reg_Type, but it could cause errors where a Data_Set entity id is used for the model or opposite.
					Then the Catalog base class could also always have a Registry<Reg_Type::index_set>, and that would simplify index_data code.
					The wrong use of the entity id is only a problem on the side of the framework implementer, and only in model_application.cpp, not on any other user. So should easily be detected. Any other way to make that better?.
					
			Have to remember to use set_serial_name during processing if we don't process the serial name during registration
			
			data_set { } declaration.
			Just let the data_set use the same AST parsing as Mobius_Model, where a [] block parses as "data", which is just a token list.
			
			Re-use the entire registry and scope structure so that we can serialize in the data set, then deserialize in the model to automatically map ids.
			
			Rename 'handle' to 'identifier'.
			
			Finish @exclude system for extend().
				e.g. extend("simplyq_model.txt") @exclude(solver(), heat : quantity)
				Should maybe change parsing so that the () on solver is unnecessary. Or is it already working like that?
				The only thing that is a bit iffy is how to handle conflicting excludes of loads of the same model. Merge the excludes, I guess?
				Also, doesn't work well with inlined declarations (which is another reason why we should rework those).
	
			Index sets refereced inside unused modules (in the data set) must still be declared in the data set.
				This could possibly be solved using data_subset (see below).
			
		
		Specific models
			NIVAFjord!!
				Go over wind mixing again, it seems a bit broken.
					Issue is that in our model the upper well-mixed layers don't stay entirely well-mixed, so the wind mixing is just spent there.
				It would eventually be better to formulate mixing in terms of turbulent energy that gets transported (and spent). Then wind is just an input to that, and so is other sources.
					
				(general, but for use here)
					Make it possible to interpolate parameter values, and set parameter values based on depth.
						E.g. there is some system for assigning a value to a value, and saying what other parameter governs the ranges of the second value.
				
			EasyChem!!
			
			Finish the simple hydraulics model.
			
		Finish connection system
		
			Properly test the flux restriction refactoring.  (e.g. having [.below] in source etc. )
				Maybe broken if we have grid1d of the same connection in both source and target (?)
				
				Also it seems like Model_Instruction::restriction should either be removed or there should be two of them (?) - one for source another for target.
			
			Dependency system for connection aggregations is very error prone and complicated. Esp. wrt. 'top' and 'bottom'.
				(in terms of how it is handled internally, not in terms of user-facing functionality)
				Ideally the entire system should be re-thought or restructured.
		
			Component index sets should probably be declared in the connection declaration in the model (also for directed_graph). It is too integral to how to model works to leave it to data set.
			
			Have to figure out what something like
				flux(blabla, something[vert.below], ...)				
			means. Right now the location 'something' is not used, and we only need to declare it to allow [.top] or [.specific] etc.
				Need this for NIVAFjord
			Maybe just make the syntax
					flux(blabla, next[vert.below])
			And this is what we do for all 'below' connection targets.
				Maybe still allow the shorthand though.
				Could later extend it to have different code depending on the target (for graph).
		
			graph connections
				
				Regex
					One should need to explicitly allow isolated nodes using something like    a | (....)
					Finish regex check in the general case (cycles case)
				
				For [below] accesses in code, we probably need to pre-process them to check that the units are the same in all instances etc.
					Right now we do check units during final codegen, but would maybe be good to have a system for checking correctness of everything first.
					Alternatively do unit conversions, but how?
					May have to be done inside resolve_function_tree, so we need to access the connection data there.
				
				Make it work with quantities as the node component.
					And allow aggregation weight for quantities (can for instance be used for degradation chains of isotopes or POPs where some of the mass goes away as side products).

			grid1d
				The way we go around not having a source_aggregate for these when we have something going from [below] (and maybe from [top] if that works now) is not clean and could cause problems if people want to use the in_flux aggregate in the code.
				However it also seems like a waste to make a source_aggregate when it is only needed for one of the indexes.
					Unless we make a special system for it not to have an index set dependency on the grid index in this case. That seems like a lot of work for this special case though.
				Alternatively, in the ODE codegen, directly make a subtraction of the flux (on condition of correct index).
					This is maybe the easiest, but is still a bit of work for this special case.
			
			
			.specific target:
				Maybe the @specific code AST should be tied to the var loc instead of the variable, like bling[vert.specific{ ..code }]
					Could then also allow .specific inside main code.
				Properly process the @specific function tree, incl. flags
				Check valid dependencies for the tree.
					Have to think about what types of variables it is allowed to reference.
				Clamp the index within allowed bounds or zero out the flux if the index is out of bounds (?).
					This is actually the only feature (except external_computation) currently where a user error could lead to unsafe memory accesses. Unless we add the constraints.
					Only reason not to do it is that it slows down the computation minisculely. Probably not a problem though (?!)
					
				Tridiagonal distribution of target as in original NIVAFjord (?).
				
				Allow .specific access also on identifiers on code.
				
			May need to zero out fluxes across (as in connections) the super index set if they also index over the sub index set. (mostly relevant for all_to_all, grid1d (and graph)).
			Sub-indexed series data.
			
		Bidirectional
			Should check that target unit is the same a source unit always (and not allow unit conversions (except time-related ones))
				And maybe not allow aggregation weights (or otherwise multiply by the inverse when necessary).
				We do a unit check in codegen, but may be better to do it earlier.
					Do we? Where??
		
			Have an optional test to see if non-bidirectional fluxes were negative after or during a run.
			
			Better tests for bidirectional fluxes before codegen. (That is, check that the concentration exists in the target). If it doesn't could maybe just have a warning, but then the conc in the target would have to be treated as 0.
			
			Need to check that a bidirectional flux wasn't discrete.

	
	*** Intermediate-pri ***
	
		Make it possible to declare quick_select lists of most interesting series in the dataset declaration, that then get displayed in MobiView in a separate tab. Maybe even pairs series, obs.
			Postponed to after large Data_Set refactor.
	
		@no_store :
			MobiView:
				There should maybe be a checkbox saying whether @no_store items should be displayed or not. Because sometimes we don't want them cluttering the ui, and it is confusing that they are not clickable if it was default to display them.
				
				If it is constant, could display in the stat window, just not in the plot, or even make a constant plot for it.
				
			May need a more granular system for specifying what series to store (for non-declared series).
			
			Make @no_store available for @override quantities even on solvers.
				I.e. for all declared variables that are not is_mass_balance_quantity().
			
			Determine variables that are going to be run-time constant and just compute them in the initial step, not the rest. (Also goes for stored variables).
				Not allowed for 'quantity' unless it is @override.
					Due to difficulty of determining what it will look like before the code generation step (the way it is set up now).
				A bit annoying if the @initial code for it is different from the main code..
				
				Could also be done for variables that are not @no_store in the outset. They could be promoted as no_store.
		
		Data_Set
			Need a reshape() function on the Data_Set or something like that, which updates all data based on new indexes for the index sets.
				Must go through everything that is indexed and delete items that are attached to removed indexes.
					parameters, connections, input series.
						anything else?
			
			Make it possible to make a data file that is referring to another one, but with a subset of the indexes.
				Just uses reshape after loading the Data_Set in the one referred to.
			e.g.
				data_subset("other file name.dat") {
					index_set() ....
				}
				Have to decide what to do with broken connection arrows.
			
			Postponed to after big Data_Set refactor.
				
		Allow index sets to be empty (needed for above to work).
			Invalidate state variables that are dependent on empty index sets.
			e.g. allows you to run EasyLake-SimplyCNP without lakes, which can be useful if you are working with a data set subset.
	
	
		Clean up the sorting algorithm
			Make it independent of the Mobius framework code (no direct error exits, instead have error codes).
	
		Can get warning if you load a library that loads another library, but you don't use all the functions of that library.
			Maybe just don't give intra-library warnings, or instead process all the functions somehow, but that is tricky.

		
		Allow averaging input values that are assigned to the same time step (makes it easier to work with different step sizes.)
		
		What to do with discrete fluxes when varying step size.
			They are currently not step size independent.
			Should they be re-scaled somehow if the step size is different from the one that is declared in the flux?
				That would only be correct if the flux is of the form dx/dt = -b*x
			
		What to do about things like (computed) global radiation that should really have an hourly variation with low step sizes but should be averaged with higher?
			
		Saving data_set docstring newline increase.
		
		Warning on HUGE allocations.
		
		Union index sets
			say     a : index_set("A") @union(b, c)
			We probably have to disallow dependency on a if you have dependency on both b and c, or it is ambiguous.
				Already fixed for direct dependencies (parameters, index sets)
				On what level do we check this? Must be during the resolution loop?
			A Var_Location hould not be able to both depend on a union and a member of that union
				This is currently checked per component basis, but not combined. Should be done in model_composition
		
		Clean up the prune_tree system.
			Could get rid of using Function_Scope in prune_helper?
				Tried it, but it has a bug.
			Easy to have leaks when moving and deleting nodes the way it is done now.

		Normalized file paths can be different depending on how they were loaded using relative paths. This causes it some times to try to load the same library twice, which causes a name clash.
			Need a fully standardized normalized path.

		It could probably be better if you *only* declare the time unit for the flux
			Alternatively need some way to construct units, like
				combine_unit(soil.water.oc.tox, [day-1])
				[day-1]@mul(soil.water.oc.tox)
			This has to do with module reusability, could apply the module to quantities with different units.
				
		error_print_location
			Make it print the bracket if needed.
			To make it completely correct we would need to store the scope_id in every Var_Location. Consider it?
				May be needed anyway if we put .specific code AST directly in the Var_Location.

		More on module loading and the declaration format:
				
			Dynamic module choice (based on data set)
			
			For properties, maybe always just put the unit on the property (but not on quantities obviously).
				
		
		The system of automatic solvers unnecessarily puts soil TDP on a solver in SimplyP. Should be a way to specify it not to. Or maybe even for it to detect that it is not necessary.
			Actually, this should be detected. It should be omitted because the value is an override, and none of the dependencies are on solvers. Instead of having auto-solver with an override, let the solver propagate as for properties.
			
			Should use an is_ode() type check rather than just checking decl_type==Decl_Type::quantity in many types of checks. (is_ode would be false if @override).
			
		More cleanup of State_Var system
			the way we handle regular_aggregates of fluxes is not necessarily that nice.
			organize unit_conversion_tree differently.
				and clean up how it is applied.
		Maybe have a separate lookup structure for fluxes and have the common flux things stored there.
			(in many cases we just loop over all fluxes and try to find common things for them)
			loc1, loc2, unit_conv, connection, etc.
				
		Let '/' always be a float division (promoting arguments to float always), and have a separate operator // (or similar) to force integer division in the few instances that is wanted.
			
		Go over and improve diagnostics in error messages (all over the place).
		
		external_computation :
			Lots of things to make less error prone, but...
			Just do whatever is needed when it is needed
			It is only used for NIVAFjord for now.
		
	*** Low-pri ****
	
		Solution of the solver step resolution output issue is not ideal. Not that good to cap try_h to 1 since it changes the dynamics of the solver in subsequent steps.
	
		Have a special state variable type that can record solver step resolution.
			Would only record what it ended at in that step though
	
		Datetime algorithms are slow for large dates
			Low priority since it really only comes into play if the user makes a mistake and zooms the plot in MobiView2 to much. We are normally not working with such large dates.
	
		In the tree pruning, try to merge local variables that are identical.
	
		'iterate' in function scope.
			Make the iter_tag be referencable as an iterator.
			
			i:{
				a <- a*2,
				a         if i > 10,
				iterate i otherwise
			}
			
		Maybe implement reverse iteration for grid1d
			if you have a property depending on the [below] of itself.
			Tricky since it would imply a complication of the instruction and index set dependency system for a very small special case.
	
		Make out_flux (?)
			out_flux(connection, substance) first.
			Also out_flux(substance).
			Could also have out_flux(target, substance) (And also for in_flux).
				where target is either a connection or a location.
			Replace things like 'flow' in some places? Maybe doesn't work.
			
			Or do we just wait since out_flux could always be computed with a property.
			
		Make a Token ole_get_token(VARIANT *var) that can streamline some of the excel reading.
			Or just switch to e.g. https://github.com/troldal/OpenXLSX/tree/master (but then we may lose formula evaluation?)
	
		Give proper error when externally linked function is not found.
			Currently it just doesn't compile the module functions, and only gives error when trying to look up the module functions saying *they* are not found.
			Not sure how to fix it, may have to delve into orcjit.

		Is there any way we could simplify 'aggregation_weight' and 'unit_conversion' so that they don't have to be declared like that?
		
		It can sometimes be very difficult to debug what is going on when one forgets to put a quantity on a solver and this doesn't give an error for dependency reasons.
		
		Capping of discrete fluxes from override variables not necessary?
			I.e. don't have to check if a flux with the source in a variable that is 'override' overtaxes its source.
		
		Current override system of inputs on properties is not the best. Should be possible on a per-index basis (but that requires something like input_was_provided in Mobius1)
			Similarly also want to allow inputs to override parameters.
				This is tricky to do implicitly due to how parameter names are scoped. May need a if_input_else_parameter() or something.
		
		MobiView:
		
			Plot
				
				More aggregation intervals
					minute, hour, day. (esp. day).
				
				Figure out a way to make 2D plot faster
					Make it not need to update the data source if plot setup was not changed.
					Improve the drawing algorithm in ScatterDraw.
						Looks like the problem is the way TableData finds the index of a point. (For each pixel lookup, it has to iterate through a large portion of the table).
							Could make binary search, or something else.
						Also make it allow custom color gradient functions.
					Maybe:
						Make a date range for the 2D plot (when the date is the x axis) that defaults to no more than say 1000 steps (?)
							Plot is just generated for this range.
				
				stacked_share has a slow implementation.
					Should maybe not sum over all the values each time it is extracted, just do it once and store it.
				Normalized axis needs to be more robust.
				Flickering axis labels when scrolling.
				
				"Network" plot for connections. Draw the network along with amount (of some quantity(ies)) as bar plot per node. Animate over time.
					Maybe not just for connection, but for any graph of that quantity (including regular fluxes)?
					Allow multiple bars for several quantities or instances of quantities.
					
				How to do unit of sum of reach flow if the reach flow unit is in m3/s and the sum is over days?
				Could have both aggregation none and days, and in the later case it also aggregates m3/s -> m3/day .
					A bit annoying do it from a coding perspective though because you have to work with declared units, not standardized units.
					
				Trend line doesn't make sense for some aggregations.
					For sum, the trend is not the trend of the sum ..
				Make the residual trend one of the available residual statistics (in terms of optim. it should be minimized in absolute value).
			
			Sensitivity & optimization - new features
				
				Make the code better so that it is not so easy to have bugs when adding/removing/moving parameters.
				Combine simple sensitivity into the advanced sensitivity setup.
					Compute statistics of the target stat like variance etc.
					Allow for 2 parameters, with a surf plot eventually.
				Serialize sensitivity setups using a Mobius format instead of json so that we can load the same setups in mobipy eventually.
				More customizable target functions.
				Targets computed from aggregate series (stats of aggregate series).
				
				Optimizer callback doesn't update additional plot view.
				
				Selection of matrix column parameters is incorrect (when you click them).
					Only when you switch from one col to another in the same row. Can only be completely fixed by moving to using GridCtrl.
				
				Implement the MCMC sampler from
					https://www.econstor.eu/bitstream/10419/268226/1/1830478958.pdf
				Also maybe other samplers.
				GLUE-like sampling?
					Issue then is that parameter distribution is not determined by frequency alone, but by weight. Need to update much of the code for that.
				GLUE-like likelihood functions?
				
			Something where you can plot individual functions / state vars as functions of their inputs.
			
			Finish all missing functionality from MobiView1
				Index set editing (Will now include connection editing).
					Use Data_Set reshape functionality when that is included
								
			tweaks to the state var tree organization
				The icons in "by quantity" view are currently not that intuitive.
				Allow order by flux? By module?
				
			
			
		
		More mobipy functionality.
			Multidimensional slices and strides
			Slices for parameters (setting and getting)
			Setting series data.
			Saving to file (incl saving inputs, but that should be a core Mobius2 feature).
			More python wrapper stuff from Mobius1.
		
		Some kind of system for specifying assertion checks on user provided data, such as
			lu_prop should sum to 1 over landscape units.
			Some parameter bounds are absolute.
	
	
		Make it possible to free file memory before a model is deleted.
			Requires ASTs to copy some string data, which is a bit annoying since right now they store Tokens directly (which contain String_Views to file memory).
			May need a way to copy String_View values over to a separate buffer for all tokens in ASTs.
			Or the ASTs just store a new struct that contains much the same as Token, but has std::strings instead.
		
		Set units of regular aggregation state variables so that they display correctly if viewed.
			note that it is a bit tricky for fluxes.
			
		aggregate() of series and parameters, or even of arbitrary expressions.
			For parameters, ideally it should just be computed once using the constant system described above.
			For arbitrary expressions, it could be tricky to figure out what compartment it actually aggregates from.
		
		Make discrete fluxes work like other fluxes for aggregation stuff so that everything works the same way for them (including some connection stuff).
			Reimplement discrete fluxes for connections in some situations.
				Should always be possible for grid1d.
				Also for graph if it is no_cycles and we force those to be ordered correctly.
			This may not go well with the above suggested change though.
		
		Would like to get the assembly code for the model, but it is apparently notrivial. Can get the obj by using a dummy object cache that dumps the memory
			https://github.com/llvm/llvm-project/blob/main/llvm/examples/OrcV2Examples/LLJITWithObjectCache/LLJITWithObjectCache.cpp
			One could then manually disassemble it.
		
		Other solver algorithms.
		
		Declaring units with a handle and reusing that handle does not quite work, at least not for parameters.
		
		last(something) doesn't automatically cause it to have an initial value computation (if one was not set).
		
		Error if you access time.fractional_step outside a solver? Or it just defaults to 0?

		Re-consolidate input loading with the serialization system (In terms of how it looks up ids of names).
			Tricky...
			
		Allow accessing e.g. conc(water.sed.phos, water) in code? Probably unnecessary ( since it is equal to conc(water.sed.phos)*conc(water.sed) )
		
		
	Probably not ?:
	
		Do reassignable local vars with phi nodes instead of alloca.
			LLVM optimizer seems to figure this one out, so it is not that important.
	
		Consider just adding connection fluxes to derivatives as they are computed instead of having so many aggregates (except when these are actually needed, which would be only when we explicitly look up the in_flux).
					This would be a major change, but could create some speedup.
					Maybe not that needed now that they are @no_store by default.
	
		System for specifying different display variants (along with the code in MobiView2 to make use of that).
			E.g. say if a variable should not be displayed in MobiView2 (but have a display all checkbox button that re-enable them)
			Maybe not really needed, @no_store is probably sufficient.
	
		If a dissolved substance can flow somewhere, you don't have to declare that it is there (?)
			Maybe only if you specify it to disperse.
			could be tricky wrt units.
			could be tricky since right now we assume all quantities are declared.
			how to determine initial value?
			sometimes you don't want it there (though that could be accomplished with no_carry)
	
		Selecting profile or profile2d should select all the indexes if only one index set is active and only one index is selected.
			Maybe not desirable
	
		The "loose depends" system is kind of iffy.
			I think there are no guarantee that something is not placed in a for loop too late initially. Esp. bc of how create_batches works.
				This in particular may have been fixed now.
				
		Load modules from modules (?)
			Probably difficult wrt. multiple loads of the same base module. Unless we also scope the module names recursively.
			Doesn't seem to be that necessary.
	
	NOTES
		
	Hope for reply on one of these 
		https://discourse.llvm.org/t/how-to-generate-ir-so-that-the-loop-vectorizer-can-vectorize-it/69096/2
		https://stackoverflow.com/questions/75674759/llvm-loop-vectorizer-does-not-vectorize-my-ir?noredirect=1#comment133504571_75674759
		