

	*** High pri ***
	
		After identifier resolution refactor:
			Do we check anywhere that fluxes can't go to 'above'? (with proper error message)?
	
		We have experimentally added some prune_tree when setting state variable code in model_compilation and model_codegen.
			Be very careful to see if this causes any problems.
			
		Overhaul of process_location_argument and resolve_identifier. Make them better structured (branch on type of initial symbol instead of the amount of components), and combine as much code as possible for these two.
			Difficult to share that much code since you can have partial chains inside code scope.
		
		Specific models
		
			Make simple TOC same in river and lake in terms of parametrization of concentrations (and river bed).
		
			Use the new preamble functionality to avoid having global par groups in more models.
		
			Keep better track of what elevation different models want wind speed. Maybe convert between different elevations if necessary.
			
			NIVAFjord!		
				
				Finish biochemistry.
					Do we need separate NO3/NH4? Do we need Si?
					
					Sulfate reduction?
					
				More careful setup of boundary values.
					
				Go over wind mixing again, it seems a bit broken.
					Issue is that in our model the upper well-mixed layers don't stay entirely well-mixed, so the wind mixing is just spent there.
				It would eventually be better to formulate mixing in terms of turbulent energy that gets transported (and spent). Then wind is just an input to that, and so is other sources.
				
				Take into account angle of shortwave radiation as it goes down the depth (so that one gets the right attenuation). Maybe diurnal variations.
				
				(general, but for use here)
					Make it possible to interpolate parameter values, and set parameter values based on depth.
						E.g. there is some system for assigning a value to a value, and saying what other parameter governs the ranges of the second value.
				Position_Map
					Must be copied over to Model index_data also.
					Must be used whenever translating a symbol (Token or string) to an index.
					-- the way we started doing it is a bit problematic because it requires the index set dimension to be set first, but in actuality we want the number of layers to  be dependent on the layer thickness, and instead just have a max depth set by the user.
						Maybe process the index set dimensions in a pass after all position maps are set, then co-process that information along with the position maps when relevant (in this instance interpret the dimension number as a depth).
				
				Should really solve the advection/diffusion equation with Crank-Nicolson.
					A bit difficult to integrate it into the existing framework.
				
			EasyChem
				Figure out how to do effluents.
				Phyto sinking here also!
				
				Count phyto in particulate mass (when comparing to Obs SS)
				
				Shading effect on phyto light availability.
			
			// Finish the simple hydraulics model.
			
		Finish connection system
		
			Properly test the flux restriction refactoring.  (e.g. having [.below] in source etc. )
				Maybe broken if we have grid1d of the same connection in both source and target (?)
			
			Dependency system for connection aggregations is very error prone and complicated. Esp. wrt. 'top' and 'bottom'.
				(in terms of how it is handled internally, not in terms of user-facing functionality)
				Ideally the entire system should be re-thought or restructured.
		
			Component index sets should probably be declared in the connection declaration in the model (also for directed_graph). It is too integral to how to model works to leave it to data set.
			
			Have to figure out what something like
				flux(blabla, something[vert.below], ...)				
			means. Right now the location 'something' is not used, and we only need to declare it to allow [.top] or [.specific] etc.
				Need this for NIVAFjord
			Maybe just make the syntax
					flux(blabla, next[vert.below])
			And this is what we do for all 'below' connection targets.
				Maybe still allow the shorthand though.
				Could later extend it to have different code depending on the target (for graph).
		
			graph connections
				
				Regex
					Finish regex check in the general case (cycles case)
					
					Regex checking of fjord_horizontal regex is bugged for nivafjord_moss
						if the regex is switched to
						river | (river? layer+ bnd_layer?)
						it fails, so the | operator is not symmetrical somehow.
					also it doesn't fail if there is an ->out on the downstream data even though that should not be allowed by the regex.
				
				For [below] accesses in code, we probably need to pre-process them to check that the units are the same in all instances etc.
					Alternatively do unit conversions, but how?
					May have to be done inside resolve_function_tree, in that case need to access the connection data there.
					
				When it accesses [below] across an index set that has a sub-index set, it should check that the sub index set is not out of bounds (if the variable depends on it).
					Probably put in make_restriction_condition().
					Right now it doesn't break because the data is allocated and has value 0, but that should not be the case eventually.
						Moreover it would be wrong if it was a flux with that target and not set to 0 for some other reason.
				
				Make it work with quantities as the node component.
					And allow aggregation weight for quantities (can for instance be used for degradation chains of isotopes or POPs where some of the mass goes away as side products).

			grid1d
				The way we go around not having a source_aggregate for these when we have something going from [below] (and maybe from [top] if that works now) is not clean and could cause problems if people want to use the in_flux aggregate in the code.
				However it also seems like a waste to make a source_aggregate when it is only needed for one of the indexes.
					Unless we make a special system for it not to have an index set dependency on the grid index in this case. That seems like a lot of work for this special case though.
				Alternatively, in the ODE codegen, directly make a subtraction of the flux (on condition of correct index).
					This is maybe the easiest, but is still a bit of work for this special case.
			
			
			.specific target:
				Maybe the @specific code AST should be tied to the var loc instead of the variable, like bling[vert.specific{ ..code }]
					Could then also allow .specific inside main code.
				Tridiagonal distribution of flux target as in original NIVAFjord (?).
				
			Should zero out fluxes / accesses across (as in connections) the super index set if they also index over the sub index set and the target sub index is out of bounds.
				In make_restriction_condition
			
		Bidirectional
			Should check that target unit is the same a source unit always (and not allow unit conversions (except time-related ones))
				Both for main and dissolved fluxes.
				And maybe not allow unit_conversions and aggregation_weights (or otherwise multiply by the inverse when necessary).
				
			Have an optional test to see if non-bidirectional non-mixing fluxes (with dissolvedes) were negative after or during a run.
			
			Need to check that a bidirectional flux wasn't discrete.
		Note: unit_conversion seems to work fine for @mixing, but we should test it properly. Also, it probably depends on the computed concentration in that expression being the same for dissolved ones (just not the mass variable). That is maybe also the case for @bidirectional.
	
	
		Make it possible to compose locs that have restrictions.
			Now works in the flux source/target fields. Not inside equations yet.
	
	
	*** Intermediate-pri ***
	
		If several loc() refer to one another in the wrong order, that is probably broken? Shouldn't be any valid use case for it, but it could happen on accident.
	
	
		Find a way to make it possible to specify a certain range of input dates for a data set not relying on each loaded series file.
				In case we only want to load a section of the series (if there are memory limitations or the processing is slow).
	
		MobiView :
			Make model reloads work better wrt 'quick select'.
				If the quick select tab is on
				
			Hang-up when selecting 'Aligned depth' when the indexing was wrong.
			General crashes when changing indexes in layered model.
				Two above have not happened lately..
			Having all layers selected, then switching from a variable that indexes over more layers to one with fewer:
				(or probably it is with having both selected?)
				It has not updated the selected indexes in time and there is an internal error.
				
			Seasonal aggregation.
		
		Keep track of max and min dates for given model input series separately and test against that when starting model run (only need to test against intersection of the intervals)
			A bit tricky if they are interpolated (?). In fact it is difficult to determine the intersection interval if any model inputs are interpolated.
		Clear model input series to NaN outside the individual interval.
			What to do if an input is interpolated and not 'inside'?		
		
		Codegen:
			Instead of partially generating the code for the instructions, should generate full code for each instruction including assignments and index set lookups.
				Need placeholders Math_Expr_FT for index lookups that are replaced when everything is glued together.
				Now dependency resolution for special instructions should be much easier since we could just inspect the index lookups.
				
	
		distribute() declarations are actually not needed since compartments and quantities can only be declared in the Model. Could instead just have the decl be
			compartment("Soil", sc, lu)
		like in the data set connection components.
			Maybe not, because we could want extending models to distribute differently.
			Although... they could also just @exclude and re-declare.
	
		mobipy slow to load easylake_simplycnp?
	
		Doubling newlines when saving loaded text data..
			Should have better processing of docstrings in general.
	
		Finish moving over to having Data_Set as a Catalog, and related things.
			
			Standardize so that model and data_set loading are both in a read_from_file function on the class itself.

			Some issue with both Model and Data_Set using Entity_Id : ?
				The wrong use of the entity id is only a problem on the side of the framework implementer, and only in model_application.cpp, not on any other user. Any way to make errors easier to detect?
	
		Data_Set
			Need a reindex() function on the Data_Set or something like that, which updates all data based on new indexes for the index sets.
				Must go through everything that is indexed and delete items that are attached to removed indexes.
					parameters, connections, input series.
						anything else?
			
			Make it possible to make a data file that is referring to another one, but with a subset of the indexes.
				Just uses reshape after loading the Data_Set in the one referred to.
			e.g.
				data_subset("other file name.dat") {
					index_set() ....
				}
				Have to decide what to do with broken connection arrows.
			
		Allow index sets to be empty (needed for above to work).
			Invalidate state variables that are dependent on empty index sets.
			e.g. allows you to run EasyLake-SimplyCNP without lakes, which can be useful if you are working with a data set subset.
		
		
		@no_store :
			MobiView:
				There should maybe be a checkbox saying whether @no_store items should be displayed or not. Because sometimes we don't want them cluttering the ui, and it is confusing that they are not clickable if it was default to display them.
				
				If it is constant, could display in the stat window, just not in the plot, or even make a constant plot for it.
				
			May need a more granular system for specifying what series to store (for non-declared series).
			
			Make @no_store available for @override quantities even on solvers.
				I.e. for all declared variables that are not is_mass_balance_quantity().
			
			Determine variables that are going to be run-time constant and just compute them in the initial step, not the rest. (Also goes for stored variables).
				Not allowed for 'quantity' unless it is @override.
					Due to difficulty of determining what it will look like before the code generation step (the way it is set up now).
				A bit annoying if the @initial code for it is different from the main code..
				
				Could also be done for variables that are not @no_store in the outset. They could be promoted as no_store.
		
	
		Can get warning if you load a library that loads another library, but you don't use all the functions of that library.
			Maybe just don't give intra-library warnings, or instead process all the functions somehow, but that is tricky.

		
		Allow averaging input values that are assigned to the same time step (makes it easier to work with different step sizes.)
		
		What to do with discrete fluxes when varying step size.
			They are currently not step size independent.
			Should they be re-scaled somehow if the step size is different from the one that is declared in the flux?
				That would only be correct if the flux is of the form dx/dt = -b*x
			
		What to do about things like (computed) global radiation that should really have an hourly variation with low step sizes but should be averaged with higher?
		
		Warning on HUGE allocations.
		
		Union index sets
			say     a : index_set("A") @union(b, c)
			We probably have to disallow dependency on a if you have dependency on both b and c, or it is ambiguous.
				Already fixed for direct dependencies (parameters, index sets)
				On what level do we check this? Must be during the resolution loop?
			A Var_Location should not be able to both depend on a union and a member of that union
				This is currently checked per component basis, but not combined. Should be done in model_composition
			Declaring a union index set before one of its members may break index processing.
		
		Clean up the prune_tree system.
			Could get rid of using Function_Scope in prune_helper?
				Tried it, but it has a bug.
			Easy to have leaks when moving and deleting nodes the way it is done now.

		Normalized file paths can be different depending on how they were loaded using relative paths. This causes it some times to try to load the same library twice, which causes a name clash.
			Need a fully standardized normalized path.

		It could probably be better if you *only* declare the time unit for the flux
			Alternatively need some way to construct units, like
				combine_unit(soil.water.oc.tox, [day-1])
				[day-1]@mul(soil.water.oc.tox)
			This has to do with module reusability, could apply the module to quantities with different units.
				
		error_print_location
			Make it print the bracket if needed.
			To make it completely correct we would need to store the scope_id in every Var_Location. Consider it?
				May be needed anyway if we put .specific code AST directly in the Var_Location.

		More on module loading and the declaration format:
				
			Dynamic module choice (based on data set)
			
			For properties, maybe always just put the unit on the property (but not on quantities obviously).

			
		The way we handle regular_aggregates of fluxes is a bit confusing when maintaining the framework.
				
		Let '/' always be a float division (promoting arguments to float always), and have a separate operator // (or similar) to force integer division in the few instances that is wanted.
			
		Go over and improve diagnostics in error messages (all over the place).
		
		external_computation :
			Lots of things to make less error prone, but...
			Just do whatever is needed when it is needed
			It is only used for NIVAFjord for now.
			
		Many times if some code depends on .below, it has a branch per lookup.
			Could instead detect if the code depends on .below and then do a branch of the code total.
			Also, could make existing_condition work for graph lookups better I think (?).
		
		The clamping of .specific expands the generated code a lot since it is done on every lookup. Maybe instead it should be tracked as a single state variable that is clamped, and just reference it.
			Not possible for .specific in code (if we allow that), only if it is the target of a flux.
		
	*** Low-pri ****
	
		When something is @override_conc we could just drop computing the mass variable whatsoever. It doesn't seem to be interesting to have.
			It could technically be referenced in code, that is the problem. We would have to detect for that.
	
		Multiple solvers:
			Eventually may want/need to codegen smoothing or means. That is if a solver looks up something from another solver, it should linearly interpolate between last() value and current value using the time.fractional_step
			May also want to compute (volume-weighted) means.
		
		Clean up the sorting algorithm
			Make it independent of the Mobius framework code (no direct error exits, instead have error codes).
	
		Solution of the solver step resolution output issue is not ideal. Not that good to cap try_h to 1 since it changes the dynamics of the solver in subsequent steps.
	
		Have a special state variable type that can record solver step resolution.
			Would only record what it ended at in that step though
	
		Datetime algorithms are slow for large dates
			Low priority since it really only comes into play if the user makes a mistake and zooms the plot in MobiView2 to much. We are normally not working with such large dates.
	
		In the tree pruning, try to merge local variables that are identical.
	
		'iterate' in function scope.
			Make the iter_tag be referencable as an iterator.
			
			i:{
				a <- a*2,
				a         if i > 10,
				iterate i otherwise
			}
			
		Maybe implement reverse iteration for grid1d
			if you have a property depending on the [below] of itself.
			Tricky since it would imply a complication of the instruction and index set dependency system for a very small special case.
	
		Make out_flux (?)
			out_flux(connection, substance) first.
			Also out_flux(substance).
			Could also have out_flux(target, substance) (And also for in_flux).
				where target is either a connection or a location.
			Replace things like 'flow' in some places? Maybe doesn't work.
			
			Or do we just wait since out_flux could always be computed with a property.
			
		Make a Token ole_get_token(VARIANT *var) that can streamline some of the excel reading.
			Or just switch to e.g. https://github.com/troldal/OpenXLSX/tree/master 
			Will probably not lose formula evaluation since that seems to be stored in the file.
	
		Give proper error when externally linked function is not found.
			Currently it just doesn't compile the module functions, and only gives error when trying to look up the module functions saying *they* are not found.
			Not sure how to fix it, may have to delve into orcjit.

		Is there any way we could simplify 'aggregation_weight' and 'unit_conversion' so that they don't have to be declared like that?
		
		It can sometimes be very difficult to debug what is going on when one forgets to put a quantity on a solver and this doesn't give an error for dependency reasons.
		
		Capping of discrete fluxes from override variables not necessary?
			I.e. don't have to check if a flux with the source in a variable that is 'override' overtaxes its source.
		
		Current override system of inputs on properties is not the best. Should be possible on a per-index basis (but that requires something like input_was_provided in Mobius1)
			Similarly also want to allow inputs to override parameters.
				This is tricky to do implicitly due to how parameter names are scoped. May need a if_input_else_parameter() or something.
		
		MobiView:
		
			Plot
				
				More aggregation intervals
					minute, hour, day. (esp. day).
				
				Figure out a way to make 2D plot faster
					Make it not need to update the data source if plot setup was not changed.
					Improve the drawing algorithm in ScatterDraw.
						Looks like the problem is the way TableData finds the index of a point. (For each pixel lookup, it has to iterate through a large portion of the table).
							Could make binary search, or something else.
						Also make it allow custom color gradient functions.
					Maybe:
						Make a date range for the 2D plot (when the date is the x axis) that defaults to no more than say 1000 steps (?)
							Plot is just generated for this range.
				
				stacked_share has a slow implementation.
					Should maybe not sum over all the values each time it is extracted, just do it once and store it.
				Normalized axis needs to be more robust.
				Flickering axis labels when scrolling.
				
				"Network" plot for connections. Draw the network along with amount (of some quantity(ies)) as bar plot per node. Animate over time.
					Maybe not just for connection, but for any graph of that quantity (including regular fluxes)?
					Allow multiple bars for several quantities or instances of quantities.
					
				How to do unit of sum of reach flow if the reach flow unit is in m3/s and the sum is over days?
				Could have both aggregation none and days, and in the later case it also aggregates m3/s -> m3/day .
					A bit annoying do it from a coding perspective though because you have to work with declared units, not standardized units.
					
				Trend line doesn't make sense for some aggregations.
					For sum, the trend is not the trend of the sum ..
				Make the residual trend one of the available residual statistics (in terms of optim. it should be minimized in absolute value).
			
			Sensitivity & optimization - new features
				
				Make the code better so that it is not so easy to have bugs when adding/removing/moving parameters.
				Combine simple sensitivity into the advanced sensitivity setup.
					Compute statistics of the target stat like variance etc.
					Allow for 2 parameters, with a surf plot eventually.
				Serialize sensitivity setups using a Mobius format instead of json so that we can load the same setups in mobipy eventually.
				More customizable target functions.
				Targets computed from aggregate series (stats of aggregate series).
				
				Optimizer callback doesn't update additional plot view.
				
				Selection of matrix column parameters is incorrect (when you click them).
					Only when you switch from one col to another in the same row. Can only be completely fixed by moving to using GridCtrl.
				
				Implement the MCMC sampler from
					https://www.econstor.eu/bitstream/10419/268226/1/1830478958.pdf
				Also maybe other samplers.
				GLUE-like sampling?
					Issue then is that parameter distribution is not determined by frequency alone, but by weight. Need to update much of the code for that.
				GLUE-like likelihood functions?
				
			Something where you can plot individual functions / state vars as functions of their inputs.
			
			Finish all missing functionality from MobiView1
				Index set editing (Will now include connection editing).
					Use Data_Set reshape functionality when that is included
								
			tweaks to the state var tree organization
				The icons in "by quantity" view are currently not that intuitive.
				Allow order by flux? By module?
				
			
			
		
		More mobipy functionality.
			Multidimensional slices and strides
			Slices for parameters (setting and getting)
			Setting series data.
			Saving to file (incl saving inputs, but that should be a core Mobius2 feature).
			More python wrapper stuff from Mobius1.
		
		Some kind of system for specifying assertion checks on user provided data, such as
			lu_prop should sum to 1 over landscape units.
			Some parameter bounds are absolute.
	
	
		Make it possible to free file memory before a model is deleted.
			Requires ASTs to copy some string data, which is a bit annoying since right now they store Tokens directly (which contain String_Views to file memory).
			May need a way to copy String_View values over to a separate buffer for all tokens in ASTs.
			Or the ASTs just store a new struct that contains much the same as Token, but has std::strings instead.
		
		Set units of regular aggregation state variables so that they display correctly if viewed.
			note that it is a bit tricky for fluxes.
			
		aggregate() of series and parameters, or even of arbitrary expressions.
			For parameters, ideally it should just be computed once using the constant system described above.
			For arbitrary expressions, it could be tricky to figure out what compartment it actually aggregates from.
		
		Make discrete fluxes work like other fluxes for aggregation stuff so that everything works the same way for them (including some connection stuff).
			Reimplement discrete fluxes for connections in some situations.
				Should always be possible for grid1d.
				Also for graph if it is no_cycles and we force those to be ordered correctly.
			This may not go well with the above suggested change though.
		
		Would like to get the assembly code for the model, but it is apparently notrivial. Can get the obj by using a dummy object cache that dumps the memory
			https://github.com/llvm/llvm-project/blob/main/llvm/examples/OrcV2Examples/LLJITWithObjectCache/LLJITWithObjectCache.cpp
			One could then manually disassemble it.
		
		Other solver algorithms.
		
		Declaring units with a handle and reusing that handle does not quite work, at least not for parameters.
		
		last(something) doesn't automatically cause it to have an initial value computation (if one was not set).
		
		Error if you access time.fractional_step outside a solver? Or it just defaults to 0?

		Re-consolidate input loading with the serialization system (In terms of how it looks up ids of names).
			Tricky...
			
		Allow accessing e.g. conc(water.sed.phos, water) in code? Probably unnecessary ( since it is equal to conc(water.sed.phos)*conc(water.sed) )
		
		
	Probably not ?:
	
		Do reassignable local vars with phi nodes instead of alloca.
			LLVM optimizer seems to figure this one out, so it is not that important.
	
		Consider just adding connection fluxes to derivatives as they are computed instead of having so many aggregates (except when these are actually needed, which would be only when we explicitly look up the in_flux).
					This would be a major change, but could create some speedup.
					Maybe not that needed now that they are @no_store by default.
	
		System for specifying different display variants (along with the code in MobiView2 to make use of that).
			E.g. say if a variable should not be displayed in MobiView2 (but have a display all checkbox button that re-enable them)
			Maybe not really needed, @no_store is probably sufficient.
	
		If a dissolved substance can flow somewhere, you don't have to declare that it is there (?)
			Maybe only if you specify it to disperse.
			could be tricky wrt units.
			could be tricky since right now we assume all quantities are declared.
			how to determine initial value?
			sometimes you don't want it there (though that could be accomplished with no_carry)
	
		Selecting profile or profile2d should select all the indexes if only one index set is active and only one index is selected.
			Maybe not desirable
	
		The "loose depends" system is kind of iffy.
			I think there are no guarantee that something is not placed in a for loop too late initially. Esp. bc of how create_batches works.
				This in particular may have been fixed now.
				
		Load modules from modules (?)
			Probably difficult wrt. multiple loads of the same base module. Unless we also scope the module names recursively.
			Doesn't seem to be that necessary.
	
	NOTES
		
	Hope for reply on one of these 
		https://discourse.llvm.org/t/how-to-generate-ir-so-that-the-loop-vectorizer-can-vectorize-it/69096/2
		https://stackoverflow.com/questions/75674759/llvm-loop-vectorizer-does-not-vectorize-my-ir?noredirect=1#comment133504571_75674759
		